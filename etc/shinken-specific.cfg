# Main configiguration file for Shinken processes
#
# Sample configuration used to define a simple environment:
# * one arbiter (that reads the configuration and dispatches it to all others)
# * one scheduler that schedules the checks (but doesn't launch them)
# * one poller (that launches the checks)
# * one reactionner (that sends the notifications)
# * one broker (that exposes Shinken data externally)
#
# This is a "Nagios equivalent" configuration with more performance
#
# The main configuration file is split in four sections
# * Section 1 - Shinken daemon process declaration
# * Section 2 - Module configurations
#   * Broker modules
#   * Broker modules with dependancies
#   * Retention modules
#   * Poller modules
#   * Arbiter and passive acquisition modules
#   * Reactionner modules
# * Section 3 - Realm declarations
# * Section 4 - Commented sample configurations
#
# To learn how to configure Shinken consult the wiki :
#   quickstart - http://www.shinken-monitoring.org/wiki/configure_shinken
#   reference - http://www.shinken-monitoring.org/wiki/official/configuringshinken-config

# ###############################################
# Section 1 - Shinken daemon process declarations
# ###############################################

# Arbiter daemon process declaration
#
# The arbiter is responsible for :
# * loading the configuration
# * manipulating the configuration
# * dispatching the configuration
# * validating the health of all other Shinken daemons
# * issuing global directives to Shinken daemons (kill, activate-spare, etc)
#
# WARNING - USER-INPUT-REQUIRED : change host_name with the hostname of your server
define arbiter{
    arbiter_name    Arbiter-Master
    #host_name      node1       ; result of the hostname command under Unix
    address         localhost   ; IP or DNS adress
    port            7770
    spare           0

    # Modules currently active :
    # Uncomment the line below with the desired modules
#   modules CommandFile, Mongodb, NSCA, VMWare_auto_linking, WS_Arbiter, Collectd

    # Modules available for arbiters :
#   CommandFile            : open the named pipe nagios.cmd
#   Mongodb                : load hosts from a mongodb database
#   PickleRetentionArbiter : save data before exiting
#   NSCA                   : NSCA server
#   VMWare_auto_linking    : lookup at Vphere server for dependencies
#   GLPI                   : import hosts from GLPI
#   TSCA                   : TSCA server
#   MySQLImport            : load configuration from a MySQL database
#   WS_Arbiter             : Webservice for pushing results to the arbiter
#   Collectd               : Wait collectd data, and take perfdata for services from it

    # Uncomment these lines in a HA architecture so the master
    # and slaves know how long they must wait for each other
    # HA status timers
#   check_interval          60      ; ping it every minute
#   timeout                 3       ; 'ping' timeout
#   data_timeout            120     ; 'data send' timeout
#   max_check_attempts      3       ; if at least max_check_attempts ping failed, the node is DEAD
}


# Receiver daemon process declaration
#
# The receiver is responsible for :
# * receiving passive status results
# * buffering and forwarding the data to the active arbiter
# which will then dispatch to the appropriate Scheduler for processing

define receiver{
    receiver_name       receiver-1
    address             localhost
    port                7773
    spare               0

    # Modules currently active :

    # Modules available for receivers :
#   modules       NSCA,CommandFile
    modules		Collectd

    timeout             3       ; 'ping' timeout
    data_timeout        120     ; 'data send' timeout
    max_check_attempts  3       ;  if at least max_check_attempts ping failed, the node is DEAD
    check_interval      60      ; ping it every minute

    direct_routing	1	; If 1, the receiver will directly send commands to the
    				; schedulers if it know about the hostname in the command

    # advanced options
    realm               All
}

# Scheduler daemon process declaration
#
# The scheduler is responsible for :
# * Creating the dependancy tree
# * Scheduling checks
# * Calculating states
# * Requesting actions from a reactionner
# * Buffering and forwarding results its associated broker

define scheduler{
    scheduler_name      scheduler-1     ; just the name
    address             localhost       ; ip or dns address of the daemon
    port                7768            ; tcp port of the daemon

    # optional
    spare               0               ; (0 = not a spare, 1 = is spare)
    weight              1               ; (some schedulers can manage more hosts than others)
    timeout             3               ; 'ping' timeout
    data_timeout        120             ; 'data send' timeout
    max_check_attempts  3               ; if at least max_check_attempts ping failed, the node is DEAD
    check_interval      60              ; ping it every minute

    # Modules currently active :
#   modules             PickleRetention

    # Modules available for schedulers :
#   PickleRetention    : Save data before exiting in flat file
#   MemcacheRetention  : Same, but in a memcache server
#   RedisRetention     : Same, but in a Redis server :)
#   MongodbRetention   : Same, but in a mongodb server :)
#   NagiosRetention    : only READ retention info from a nagios retention file

    # advanced options
    realm               All             ; optional (realm are multi-datacenters features)
    # skip the initial broks creation. Boot fast, but some broker modules won't work with it!
    skip_initial_broks  0

    # In NATted environments, you declare each satellite ip[:port] as seen by *this* scheduler
    # (if port not set, the port declared by satellite itself is used)
    #satellitemap poller-1=1.2.3.4:1772, reactionner-1=1.2.3.5:1773, ...
}

# Poller daemon process declaration
#
# The poller is responsible for :
# * active data acquisition
# * local passive data acquisition

define poller{
    poller_name         poller-1
    address             localhost
    port                7771

    # optional
    manage_sub_realms   0       ; optional and advanced: does it take jobs from schedulers of sub realms?
    min_workers         0       ; optional: starts with N worker processes. 0 means: "number of cpus"
    max_workers         0       ; optional: no more than N worker processes. 0 means: "number of cpus"
    processes_by_worker 256     ; optional: each worker manages 256 checks
    polling_interval    1       ; optional: get jobs from schedulers each 1 second
    timeout             3       ; 'ping' timeout
    data_timeout        120     ; 'data send' timeout
    check_interval      60      ; ping it every minute
    max_check_attempts  3       ;  if at least max_check_attempts ping failed, the node is DEAD

    # Modules to activate for the Poller
    # modules             NrpeBooster,CommandFile


    # Modules available for pollers :
    # NRPE Booster   : will skip the use of check_nrpe binary
    #  and use its own daemonized NRPE process to acquire data from remote hosts running an NRPE agent.
    # CommandFile    : can allow a nagios.cmd named pipe to be read by the
    #  poller. This permits the use of distributed check_mk checks should you desire it.

    # For DMZ monitoring, set passive 1 so the connexions will be
    # from scheduler -> poller.
    #passive    	    	   0

    # advanced options
#   poller_tags         None
    realm               All
}


# Reactionner daemon process declaration
#
# The reactionner is responsible for :
# * executing notification actions
# * executing event handler actions

define reactionner{
    reactionner_name    reactionner-1
    address             localhost
    port                7769
    spare               0

    # optional
    manage_sub_realms   0   ; optional: like for poller
    min_workers         1   ; optional: like for poller
    max_workers         15  ; optional: like for poller
    polling_interval    1   ; optional: like for poller

    timeout             3   ; 'ping' timeout
    data_timeout        120 ; 'data send' timeout
    check_interval      60  ; ping it every minute
    max_check_attempts  3   ; if at least max_check_attempts ping failed, the node is DEAD

    # Modules currently active :

    # Modules available for reactionners :
#   modules          AndroidSMS

    # advanced options
    realm               All
}

# Broker daemon process declaration
#
# The broker is responsible for :
# * exporting centralized logs of all Shinken daemon processese
# * exporting status data from Shinken
# * exporting performance data from Shinken
# * exposing Shinken APIs
#   * Status data
#   * performance data
#   * configuration data
#   * command interface
# 
# This sample configuration uses a typical configuration with the Livestatus API
# centralized logging and the Shinken WebUI module, which is the web interface.
define broker{
    broker_name     broker-1
    address         localhost
    port            7772
    spare           0

    # Modules currently active :
    modules         Livestatus, Simple-log, WebUI

    # Modules available for brokers :
#   PickleRetentionBroker   : save data in case of restarts
#   ToNdodb_Mysql           : NDO database support
#   NPCDMOD                 : Use the PNP addon
#   Graphite-Perfdata       : Export performace data to a Graphite time series database
#   WebUI                   : Shinken Web interface

    # optional
    manage_sub_realms   1       ; optional, like for poller
    manage_arbiters     1       ; optional: take data from Arbiter. There should be
                                ; only one broker for the arbiter

    check_interval      60      ; ping it every minute
    timeout             3       ; 'ping' timeout, do not increase as this is a blocking operation
    data_timeout        120     ; 'data send' timeout
    max_check_attempts  3       ; if at least max_check_attempts ping failed, the node is DEAD

    # advanced
    realm               All
}

# #################################################
# Section 2 - Shinken daemon process modules
# #################################################

# Note: Modules can only be defined in a compatible 
#       Shinken daemon process.

#### Poller Modules ##############################################

# Module: Simple-log
# LoadingDaemon: Broker
# Centralized log management module for all Shinken processes. This module consumes
# log broks (inter process messages) and exports them to a flat-file local to where the
# active broker is running.
define module{
    module_name     Simple-log
    module_type     simple_log
    path            nagios.log
    archive_path    archives/
}


# Module: Status.dat and objects.cache export.
# LoadingDaemon: Broker
# Legacy module for the old Nagios interface for migration purposes only as this is one reason
# Nagios is so dog slow. 
define module{
    module_name             Status-Dat
    module_type             status_dat
    status_file             status.dat
    object_cache_file       objects.cache
    status_update_interval  15 ; update status.dat every 15s
}

# Module: WebUI
# LoadingDaemon: Broker
# The Shinken web interface and integrated web server.
define module{
    module_name     WebUI
    module_type     webui

    host            0.0.0.0       ; all interfaces
    port            7767

    share_dir       share

    # IMPORTANT: Change this value or someone may forge cookies!
    auth_secret     CHANGE_ME

    # Allow or not the html characters in plugins output
    # WARNING: it can be a security issue
    allow_html_output   0
    # Take contact acl. Put 0 will allow actions for all contacts
    manage_acl          1

    # Uncomment to add text to the login form
    #login_text       Welcome on Shinken WebUI.

    #***** Advanced options. Do not touch it if you don't
    # know what you are doing  ****

    #http_backend    auto
    # ; can be also: wsgiref, cherrypy, paste, tornado, twisted
    # ; or gevent. auto means it tries to find the best available in the system.

    # Maybe the WebUI is behind a web server which has already authenticated the user
    # In that case use the, Remote_user, variable
    # See the documentation for an example of the configuration of Apache in front of the WebUI
    #remote_user_enable 1
    #remote_user_variable X_Remote_User


    # Modules for the WebUI.
    # - Apache_passwd     : use an Apache htpasswd files for auth
    # - ActiveDir_UI      : use AD for auth and photo collect
    # - Cfg_password      : use passwords in contacts configuration for auth
    # - PNP_UI            : Use PNP graphs in the UI
    # - GRAPHITE_UI       : Use graphs from Graphite
    # - Mongodb           : save user preferences to a Mongodb database
    modules         Apache_passwd,ActiveDir_UI,Cfg_password,PNP_UI,Mongodb

}

# Module: ActiveDir_UI
# LoadingDaemon: WebUI Broker module
# Check authentification for WebUI using Active Directory
define module{
    module_name     ActiveDir_UI
    module_type     ad_webui

    # IMPORTANT: You need to UNCOMMENT and configure the path to your LDAP server.
    #ldap_uri     ldaps://myserver

    # you must use user@domain or a full dn such as CN=user,DC=domain,DC=tld
    username        user@domain
    password        password
    basedn          DC=google,DC=com

}

# Module: Apache_passwd
# LoadingDaemon: WebUI Broker module
# Check authentification for WebUI using a apache password file
define module{
    module_name      Apache_passwd
    module_type      passwd_webui

    # IMPORTANT: use the full PATH here!
    passwd          /etc/shinken/htpasswd.users
}

# Module: Cfg_password
# LoadingDaemon: WebUI Broker module
# Check authentification for WebUI using password parameter in contact definition
define module{
    module_name      Cfg_password
    module_type      cfg_password_webui
}



#### Broker Modules with dependancies ############################

# Module: Graphit-Perfdata
# LoadingDaemon: Broker
# Export host and service performance data to Graphite carbon process.
#
# Graphite is a time series database with a rich web service
# interface, viewed as a modern alternative to RRDtool
# http://graphite.wikidot.com/start
define module{
    module_name     Graphite-Perfdata
    module_type     graphite_perfdata
    host            localhost
    port            2003        ; 2004 for pickle binary interface
}

# Module: GRAPHITE_UI
# LoadingDaemon: WebUI Broker module
# Use Graphite graphs in the WebUI, based on default or graphite URL API templates
define module{
    module_name     GRAPHITE_UI
    module_type     graphite_webui
    uri             http://YOURSERVERNAME/  ; put the real Graphite web URI here. YOURSERVERNAME
                                            ; replaced by the hostname of the server
    templates_path /usr/local/shinken/share/templates/graphite/

}

# Module: NPCDMOD
# LoadingDaemon: Broker
# Module to send host and service perfdata to a NPCD daemon,
# which makes the data available to PNP4Nagios.
define module{
    module_name  NPCDMOD
    module_type  npcdmod
    config_file  /usr/local/pnp4nagios/etc/npcd.cfg
}

# Module: PNP_UI
# LoadingDaemon: WebUI Broker module
# Use PNP graphs in the Shinken WebUI web interface
define module{
    module_name     PNP_UI
    module_type     pnp_webui
    uri             http://YOURSERVERNAME/pnp4nagios/   ; put the real PNP uri here. YOURSERVERNAME
                                                        ; will be replaced by the hostname of the server
}

# Module: Livestatus
# LoadingDaemon: Broker 
# The LIVESTATUS API makes internal Shinken data available via the network using an
# SQL-like syntax. The API supports various access methods, authentication and sophisticated
# performance options. The permier interface to Shinken internal host and service states,
# historical data, performance data, configuration data, comments, maintenance periods, etc.
define module{
    module_name      Livestatus
    module_type      livestatus
    host             *       ; * = listen on all configured ip addresses
    port             50000   ; port to listen
    # uncomment the socket line if you want to open
    # an unix socket for the connection
    #socket           /usr/local/shinken/var/rw/live
    modules          logsqlite

    # Prefer SQL queries if available instead of internal in-memory lookups
    # Some corner cases may return invalid or no data. Defaults to 0 if unset.
    # Only supported for sqlite databases at this time.
    #use_aggressive_sql   1   ; Set to 1 for large installations

    # Available modules:
    # - logsqlite: send historical logs to a local sqlite database
    # - mongologs: send historical logs to a mongodb database

    # Only set debug if you're having problems with this module
    #debug               /tmp/ls.debug
    # Set to 1 if you want to dump queries/responses too
    # WARNING: it is very verbose
    #debug_queries       0
}

# Module: logsqlite
# LoadingDaemon: Livestatus Broker Module
# Put the Livestatus logs in an sqlite database, and so LS can query them.
define module{
    module_name      logsqlite
    module_type      logstore_sqlite
    database_file    /usr/local/shinken/var/livelogs.db
    max_logs_age     3m ; three months. Other time intervals are d=days, w=weeks, y=years
}

# Module: mongologs
# LoadingDaemon: Livestatus Broker Module
# Put the Livestatus logs in an mongodb database, so LS can query them.
define module{
    module_name      mongologs
    module_type      logstore_mongodb
    mongodb_uri      mongodb://localhost/?safe=true
}

# Module: Syslog
# LoadingDaemon: Broker
# Send all logs to a local syslog server. Support for remote syslog can be implemented
# if requested. Just lookup the syslog module, easy to modify. Use for example with Splunk
# Molog, Logstash or other log management and analysis system.
define module{
    module_name      Syslog
    module_type      syslog
}

# Module: ToNdodb_Mysql
# LoadingDaemon: Broker
# The NDO/MySQL module for use with Centreon web frontend and configuration
# management.
define module{
    module_name     ToNdodb_Mysql
    module_type     ndodb_mysql
    database        ndo         ; database name
    user            root        ; user of the database
    password        root        ; must be changed
    host            localhost   ; host to connect to
    character_set   utf8        ; optional, utf8 is the default
    port            3306        ; mysql port
    prefix          nagios_     ; prefix for ndo tables

    # If you want to mix Shinken AND Nagios/Icinga in the same db
    # enable this. It will use in database instance_id, and not use the shinken ones
    # override/delete other ones. It can slow down the performance of the database a little.
    synchronize_database_id    0
}

# Module: Canopsis
# LoadingDaemon: Broker
# Canospis hypervisor for event management. - Experimental -
define module{
    module_name          Canopsis
    module_type          canopsis
    host                 localhost     ; host to connect to
    port                 5672          ; rabbitmq port
    user                 guest         ; must be changed
    password             guest         ; must be changed
    virtual_host         canopsis
    exchange_name        canopsis.events
    identifier           shinken-1     ; need a unique indentifier because there should be more than on shinken in canopsis
    maxqueuelength       50000         ; maximum event stored in queue when connection with canopsis is lost
    queue_dump_frequency 300           ; frequency (in seconds) on wich the queue is saved for retention
}

# Module: ToNdodb_Oracle
# LoadingDaemon: Broker
# Alternate web frontend. Export data to an Icinga web front-end.
define module{
    module_name         ToNdodb_Oracle
    module_type         ndodb_oracle
    database            XE              ;database name (listener in fact)
    user                system          ;user to connect
    password            password        ;Yes I know I have to change my default password...
    oracle_home         /usr/lib/oracle/xe/app/oracle/product/10.2.0/server     ; optional, but can be useful
}

# Module: ToMerlindb_Mysql
# LoadingDaemon: Broker
# Alternate web frontend. Export data for an op5, Ninja web front-end MySQL database.
define module{
       module_name      ToMerlindb_Mysql
       module_type      merlindb
       backend          mysql       ; backend to use, here mysql databse
       database         merlin      ; database name
       user             root        ; ? .. yes, the user of the database...
       password         root        ; wtf? you ask?
       host             localhost   ; host of the database
       character_set    utf8        ; optional, utf8 is the default
}


# Module: ToMerlindb_Sqlite
# LoadingDaemon: Broker
# Not commonly used, deprecated.
# Alternate web frontend. Export data for an op5, Ninja web front-end Merlin SQLite database.
# define module{
#     module_name      ToMerlindb_Sqlite
#     module_type      merlindb
#     backend          sqlite                  ; like the mysql, but sqlite :)
#     database_path    /tmp/merlindb.sqlite    ; path of the sqlite file
#}

# Module: ToCouchdb
# LoadingDaemon: Broker
# Not commonly used.
# NoSQL database export. Mongodb is the preferred choice via Livestatus API module.
#define module{
#    module_name     ToCouchdb
#    module_type     couchdb
#    user            root
#    password        root
#    host            localhost
#}

# Module: Service-Perfdata
# LoadingDaemon: Broker
# Export services perfdata to a flat file. For centreon or perfparse. This does not scale
# and should only be used for small installations.
define module{
    module_name     Service-Perfdata
    module_type     service_perfdata
    path            service-perfdata
    #mode           a                   ; optional. a = append, w = overwrite, p =pipe
    #template       $LASTSERVICECHECK$\t$HOSTNAME$\t$SERVICEDESC$\t$SERVICEOUTPUT$\t$SERVICEPERFDATA$\t$SERVICESTATE$\n
}


# Module: Host-Perfdata
# LoadingDaemon: Broker
# Export host perfdata to a flat file. For centreon or perfparse. This does not scale
# and should only be used for small installations.
define module{
    module_name     Host-Perfdata
    module_type     host_perfdata
    path            host-perfdata
    #mode           a               ; optional. a = append, w = overwrite, p =pipe
    #template       $LASTHOSTCHECK$\t$HOSTNAME$\t$HOSTOUTPUT$\t$HOSTSTATE$\t$HOSTPERFDATA$\n

}

#### Retention Modules ###########################################

# Module: PickleRetention
# LoadingDaemon: Scheduler
# Retention file to keep state between process restarts.
define module{
    module_name      PickleRetention
    module_type      pickle_retention_file_generic
    path             /tmp/retention.dat
}


# Module: PickleRetentionBroker
# LoadingDaemon: Broker
# Retention file to keep state between process restarts. Not actually sure what it caches!?!
define module{
    module_name      PickleRetentionBroker
    module_type      pickle_retention_file_generic
    path             /tmp/retention_broker.dat
}

# Module: PickleRetentionArbiter
# LoadingDaemon: Arbiter
# Retention file to keep state between process restarts. Not actually sure what it caches!?!
define module{
    module_name      PickleRetentionArbiter
    module_type      pickle_retention_file_generic
    path             /tmp/retention_arbiter.dat
}


# Module: NagiosRetention
# LoadingDaemon: ????
# Retention file to keep state between process restarts. Not actually sure what it caches!?!
define module{
    module_name      NagiosRetention
    module_type      nagios_retention_file
    path             /tmp/retention-nagios.dat
}


# Module: MongodbRetention
# LoadingDaemon: Scheduler
# Retention file to keep state between process restarts.
define module{
    module_name     MongodbRetention
    module_type     mongodb_retention
    uri             mongodb://localhost/?safe=true
    database        shinken
}


# Module: MemcacheRetention
# LoadingDaemon: Scheduler
# Retention file to keep state between process restarts in resident memory. Data loss occurs
# if the server restarts and memcache replication is not enabled between two memcached instances.
define module{
    module_name      MemcacheRetention
    module_type      memcache_retention
    server           127.0.0.1
    port             11211
}


# Module: RedisRetention
# LoadingDaemon: Scheduler
# Retention file to keep state between process restarts in resident memory. Data loss occurs
# if the server restarts and Redis replication is not enabled between two Redis instances.
define module{
    module_name      RedisRetention
    module_type      redis_retention
    server           127.0.0.1
}

# Module: Mongodb
# LoadingDaemon: Arbiter, WebUI Broker module
# Arbiter: Read objects in a mongodb database (like hosts or services)
# WebUI  : save/read user preferences
define module{
    module_name     Mongodb
    module_type     mongodb
    uri             mongodb://localhost/?safe=true
    database        shinken
}

#### Poller Modules ##############################################

# Module: NrpeBooster
# LoadingDaemon: Poller module
# NRPE commands tagged with nrpe_poller as module_type will be managed 
# by this module. It will bypass the launch of check_nrpe, and will do the
# connection itself. You should not use check_nrpe with Shinken.
define module{
    module_name     NrpeBooster
    module_type     nrpe_poller
}

#### Arbiter and Passive acquisition Modules ######################

# Module: NSCA
# LoadingDaemon: Arbiter, Receiver
# Receive check results sent using send_nsca scripts
define module{
    module_name       NSCA
    module_type       nsca_server
    host              *
    port              5667
    encryption_method 1
    password          helloworld
}

# Module: CommandFile
# LoadingDaemon: Poller, Arbiter and Receiver
# Receive passive host and service results typically from check_mk plugins.
# Restricted to host and service results, not other commands or inputs accepted.
define module{
    module_name      CommandFile
    module_type      named_pipe
    command_file     rw/nagios.cmd
}

# Module: Collectd
# LoadingDaemon: Arbiter and Receiver
# Receive passive host and service results from collectd.
define module{
    module_name      Collectd
    module_type      collectd
}

# Module: TSCA
# LoadingDaemon: Arbiter, Receiver
# Receive check results using TSCA, a thrift interface
define module{
    module_name     TSCA
    module_type     tsca_server
    host            *
    port            9090
}


# Module: GLPI
# LoadingDaemon: Arbiter
# GLPI Inventory and configuration management Application
# You can load configuration from this app (with
# the webservices plugins for GLPI, in xmlrpc mode and with plugin
# monitoring for GLPI)
# =============== Work with Plugin Monitoring of GLPI ===============
# All configuration read from this will be added to the others of the
# standard flat file
define module{
    module_name     GLPI
    module_type     glpi
    uri             http://localhost/glpi/plugins/webservices/xmlrpc.php
    login_name      glpi
    login_password  glpi
    tag
}

# Module: glpidb
# LoadingDaemon: Broker
# Export data to the glpi database from a Shinken broker.
# =============== Work with Plugin Monitoring of GLPI ===============
define module{
    module_name       glpidb
    module_type       glpidb
    database          glpi        ; database name
    user              root        ; database user
    password          root        ; must be changed
    host              localhost   ; host to connect to
}


# Module: VMWare_auto_linking
# LoadingDaemon: Arbiter
# Follow your hosts in a virtual infrastructure.
# Mapping dependancies following VMotions. With this module, you can
# just connect to vcenter from time to time and update dependencies.
# Arbiter restart required to apply updated configurations.
define module{
    module_name             VMWare_auto_linking
    module_type             hot_dependencies
    mapping_file            /tmp/vmware_mapping_file.json
    mapping_command         /usr/local/shinken/libexec/link_vmware_host_vm.py -x '/usr/local/shinken/libexec/check_esx3.pl' -V 'vcenter.mydomain.com' -u 'admin' -p 'secret' -r 'lower|nofqdn'  -o /tmp/vmware_mapping_file.json
    mapping_command_interval    60      ; optional
    mapping_command_timeout     300     ; optional

    # Only useful if you want debug output. Can be verbose for large
    # installations
    #debug                    1
}

# Module: External_auto_linking
# LoadingDaemon: Arbiter
# Another way to update dependencies is to update a flat file
# See some examples to do that in the python script
define module{
    module_name      External_auto_linking
    module_type      hot_dependencies
    mapping_file     /tmp/external_mapping_file.json
    mapping_command  /usr/local/shinken/libexec/external_mapping.py -i /tmp/shinken_flat_mapping -o /tmp/external_mapping_file.json
    mapping_command_interval  60   ; optional
    mapping_command_timeout   300 ; optional
}

# Module: HackCommandsPollerTag
# LoadingDaemon: Arbiter
# Change on the fly a poller tag of a command by another.
# Useful when you use a fixed configuration tool that doesn't allow you
# to configure poller_tag.
define module{
    module_name     HackCommandsPollerTag
    module_type     hack_commands_poller_tag
    cmd_line_match  (.*)check_esx3(.*)
    poller_tag      esx3
}

# Module: HackPollerTagByMacros
# LoadingDaemon: Arbiter
# Arbiter module to change on the fly a poller tag of hosts
# and services by searching for a custom macro
# Useful when you use a fixed configuration tool that doesn't allow you
# to configure poller_tag.
define module{
    module_name          HackPollerTagByMacros
    module_type          hack_poller_tag_by_macros
    host_macro_name      _poller_tag
    service_macro_name   _poller_tag
}

# Module: MySQLImport
# LoadingDaemon: Arbiter
# Hosts, Services, Contacts and Dependencies configuration can be pulled from a MySQL database
# All hosts,services,contacts and dependencies read from the database will be added to the others of the
# standard flat file.
# You can easily use an existing database, you just have to define the queries to suit your database
# It can be a useful module to use for HA too :)
define module{
    module_name      MySQLImport
    module_type      mysql_import
    host             localhost
    login            root
    password         azerty
    database         supervision
    reqhosts         SELECT host_name, alias, realm, address ,template AS 'use' FROM hosts
    reqservices      SELECT host_name, service_description, normal_check_interval, check_command ,template AS 'use' FROM services
    reqcontacts      SELECT contact_name, email, template AS 'use' FROM contacts
    reqcontactgroups SELECT contactgroup_name, members FROM contactgroups
    reqhostdependencies      SELECT host_name, dependent_host_name, notification_failure_criteria FROM hostdependencies
    reqservicedependencies   SELECT host_name, service_description, dependent_host_name, dependent_service_description, execution_failure_criteria, notification_failure_criteria FROM servicedependencies
    reqrealms        SELECT realm_name, realm_members, `default` FROM realms
    reqschedulers    SELECT scheduler_name, address, port, spare, realm, modules FROM schedulers
    reqpollers       SELECT poller_name, address, port, spare, realm, manage_sub_realms, poller_tags, modules FROM pollers
    reqreactionners  SELECT reactionner_name, address, port, spare, realm, manage_sub_realms, modules FROM reactionners
    reqbrokers       SELECT broker_name, address, port, spare, realm, manage_sub_realms, modules FROM brokers
    reqreceivers     SELECT receiver_name, address, port, spare, realm, manage_sub_realms, modules FROM receivers
}

# Module: IpTag
# LoadingDaemon: Arbiter
# Will "tag" hosts by looking at their hostadress, and find the IP.
#
# If the IP is in the address range defined below, it will apply the property with
# the value as if the line
#   property  value
# was in the definition of the host.
# Method: replace or append
# - replace will put the value if not another one is in place
# - append will add with a , if a value already exist
define module{
    module_name     IpTag
    module_type     ip_tag
    ip_range        127.0.0.0/30
    property        poller_tag    ; property to modify
    value           LOCAL         ; value to append resp. use

    # optional
    method          replace       ; either replace or append
}


# Module: WS_Arbiter
# LoadingDaemon: Arbiter, Receiver
# WebService module for the arbiter and Receiver so you can send (POST)
# passive checks to it :)
define module{
    module_name     WS_Arbiter
    module_type     ws_arbiter
    host            0.0.0.0
    port            7760
    username        anonymous       ; if you want auth, change anonymous and
    #password       secret          ; uncomment the password line
}

#### Reactionner Modules ##############################################

# Reactionner can be launched under an android device
# and can be used it to send SMS with this module
define module{
    module_name     AndroidSMS
    module_type     android_sms
}

# #################################################
# Section 3 - Shinken Realm management
# #################################################

# Advanced feature for multisite management.
# Read the documentation VERY CAREFULLY before changing these settings
define realm{
    realm_name  All
    default     1
}

# #################################################
# Section 4 - Sample configurations
# #################################################

# Sample of an android SMS reactionner.
# 2 requirements:
# * modules AndroidSMS: so you will load SMS sending code
# * reactionner_tags android_sms: so ONLY commands with this tag will
#   be sent to this reactionner, no mails or event handlers.
#define reactionner{
#   reactionner_name    reactionner-Android
#   address             WIFI-IP-OF-YOUR-ANDROID-PHONE
#   port                7769
#   spare               0
#
#   timeout             3           ; 'ping' timeout
#   data_timeout        120         ; 'data send' timeout
#   check_interval      60          ; ping it every minute
#   max_check_attempts  3           ; if at least max_check_attempts ping failed, the node is DEAD
#
#   # Modules
#   modules             AndroidSMS
#
#   reactionner_tags    android_sms
#
#   # optional
#   realm               All
#}


# Reactionner can be launched under an android device
# and can be used it to send SMS with this module
define module{
    module_name     AndroidSMS
    module_type     android_sms
}





